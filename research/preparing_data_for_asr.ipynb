{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e2829a",
   "metadata": {},
   "source": [
    "# Подготовка данных для ASR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef82b9",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3dd55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from dataset import IPS1ASRDataset\n",
    "from utils import clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02e20c",
   "metadata": {},
   "source": [
    "## Датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74b6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_dataset_train = IPS1ASRDataset('../tatar_tts/train/')\n",
    "ips_dataset_valid = IPS1ASRDataset('../tatar_tts/valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb6ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_dataset_to_df(dataset: Dataset) -> pd.DataFrame:\n",
    "    data = []\n",
    "    for index in range(len(dataset)):\n",
    "        item = dataset.get_metadata(index)\n",
    "        text = clean_text(item[2])\n",
    "        item_dict = {\n",
    "            'id': str(item[0].split('/')[-1][:-4]),\n",
    "            # 'name': item[0].split('/')[-1],\n",
    "            # 'path': item[0],\n",
    "            'text': text,\n",
    "            'len': len(text),\n",
    "            'word_count': len(text.split())\n",
    "        }\n",
    "        data.append(item_dict)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index('id')\n",
    "    del data\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3547fd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../tatar_tts/train/331.26.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m from_dataset_to_df(ips_dataset_train)\n\u001b[1;32m      2\u001b[0m df_valid \u001b[38;5;241m=\u001b[39m from_dataset_to_df(ips_dataset_valid)\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mfrom_dataset_to_df\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m----> 4\u001b[0m     item \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_metadata(index)\n\u001b[1;32m      5\u001b[0m     text \u001b[38;5;241m=\u001b[39m clean_text(item[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      6\u001b[0m     item_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(item[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]),\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# 'name': item[0].split('/')[-1],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(text\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m     13\u001b[0m     }\n",
      "File \u001b[0;32m~/projects/speach/research/dataset.py:51\u001b[0m, in \u001b[0;36mIPS1ASRDataset.get_metadata\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_metadata\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     50\u001b[0m     audio_sample_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_audio_sample_path(index)\n\u001b[0;32m---> 51\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_audio_sample_label(index)\n\u001b[1;32m     52\u001b[0m     signal, sample_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(audio_sample_path)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (audio_sample_path, sample_rate, label, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/projects/speach/research/dataset.py:38\u001b[0m, in \u001b[0;36mIPS1ASRDataset._get_audio_sample_label\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_audio_sample_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     37\u001b[0m     label_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(label_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     39\u001b[0m         label \u001b[38;5;241m=\u001b[39m clean_text(f\u001b[38;5;241m.\u001b[39mread()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monly_char \u001b[38;5;28;01melse\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread() \u001b[38;5;66;03m# Не учитывает ошибки в заполнение .txt\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m label\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../tatar_tts/train/331.26.txt'"
     ]
    }
   ],
   "source": [
    "df_train = from_dataset_to_df(ips_dataset_train)\n",
    "df_valid = from_dataset_to_df(ips_dataset_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa747b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e0f90",
   "metadata": {},
   "source": [
    "## Исследование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212f29e",
   "metadata": {},
   "source": [
    "### Длина текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffecea",
   "metadata": {},
   "source": [
    "#### value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['len'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd65256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['word_count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4012c370",
   "metadata": {},
   "source": [
    "#### Гистограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48289b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['len'].hist(bins=25)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['word_count'].hist(bins=25)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b183540",
   "metadata": {},
   "source": [
    "#### Ящик с усами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.boxplot(column='len')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16eccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.boxplot(column='word_count')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09519942",
   "metadata": {},
   "source": [
    "#### describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['word_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e21fa",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49011d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(2 < df_train['word_count']) & (df_train['word_count'] < 11)].shape[0] / df_train.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ced5b",
   "metadata": {},
   "source": [
    "Удалим 10% данных, которые являются выбросами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1dc504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[(2 < df_train['word_count']) & (df_train['word_count'] < 11)]\n",
    "df_valid = df_valid.loc[(2 < df_valid['word_count']) & (df_valid['word_count'] < 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../tatar_tts/train.csv')\n",
    "df_valid.to_csv('../tatar_tts/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6088b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc['331.90']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973da446",
   "metadata": {},
   "source": [
    "### Цифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecfef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_digits(text):\n",
    "    numbers = re.findall(r'\\d+', text)\n",
    "    return numbers == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_digits('бөгелеп төшмәве') == True, 'Неверная работа функции get_digits'\n",
    "assert get_digits('бөгелеп төшмәве 1') == False, 'Неверная работа функции get_digits'\n",
    "assert get_digits('1 бөгелеп төшмәве 2') == False, 'Неверная работа функции get_digits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['numbers'] = df_train['text'].apply(lambda row: get_digits(row))\n",
    "df_valid['numbers'] = df_valid['text'].apply(lambda row: get_digits(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d57f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['numbers'] == False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42085a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.loc[df_valid['numbers'] == False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ac41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['numbers'] == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e363a075",
   "metadata": {},
   "source": [
    "Найдено 33 строки в тренировочном наборе данных, в которых встречаюся числительные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680acad6",
   "metadata": {},
   "source": [
    "### Специальные символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_dijits(text):\n",
    "    special_characters = '@#$%^&*()-+_=<>/\\'\":;[]{}\\\\|~`!?,.'\n",
    "    for char in text:\n",
    "        if char in special_characters:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121709dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_char_dijits('бөгелеп төшмәве') == True, 'Неверная работа функции get_digits'\n",
    "assert get_char_dijits('бөгелеп төшмәве \"\"') == False, 'Неверная работа функции get_digits'\n",
    "assert get_char_dijits('1 бөгелеп төшмәве ..\\\\||') == False, 'Неверная работа функции get_digits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['char_dijits'] = df_train['text'].apply(lambda row: get_char_dijits(row))\n",
    "df_valid['char_dijits'] = df_valid['text'].apply(lambda row: get_char_dijits(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['char_dijits'] == False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6715f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['char_dijits'] == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.loc[df_valid['char_dijits'] == False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa04fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.loc[df_train['char_dijits'] == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3df100",
   "metadata": {},
   "source": [
    "Мы разрешаем иметь в данных !?, символы. остальные нужно будет удалить из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14728eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "asr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
