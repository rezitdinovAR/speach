{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibD6bsRPl8Qu"
   },
   "source": [
    "# Building an end-to-end Speech Recognition model in PyTorch - [AssemblyAI](https://www.assemblyai.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1fXgsDQmK09"
   },
   "source": [
    "## installing the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwfN8o17Bdp2",
    "outputId": "d6cb1926-fc3c-4ac7-b551-1eaf69c04c0f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install comet-ml==3.0.2 -qq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-04 16:32:19,558] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from comet_ml import Experiment\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from accelerate.utils import set_seed\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "from dataset import IPS1ASRDataset\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSKHvy8DmOCQ"
   },
   "source": [
    "## Setting up your data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_arr = [\n",
    "            '<SPACE>', 'а', 'ә', 'б', 'в', 'г', 'д', 'е', 'ё', 'ж', 'җ', 'з', 'и', 'й', 'к', 'л',\n",
    "            'м', 'н', 'ң', 'о', 'ө', 'п', 'р', 'с', 'т', 'у', 'ү', 'ф', 'х', 'һ', 'ц', 'ч', 'ш', 'щ',\n",
    "            'ъ', 'ы', 'ь', 'э', 'ю', 'я'\n",
    "        ]\n",
    "\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for index in range(len(char_map_arr)):\n",
    "            ch = char_map_arr[index]\n",
    "            self.char_map[ch] = index\n",
    "            self.index_map[index] = ch\n",
    "        self.index_map[0] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to \n",
    "        an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            elif c in self.char_map:\n",
    "                ch = self.char_map[c]\n",
    "            else: \n",
    "                continue\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to \n",
    "        an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('<SPACE>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "text_transform = TextTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _, _, _) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'valid':\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "        spectrograms.append(spec)\n",
    "        utterance = utterance.lstrip('\\ufeff')\n",
    "        \n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVJs4Bk8FjjO",
    "outputId": "e17f3aa9-5973-4f22-af9d-43b6fff89e3a"
   },
   "outputs": [],
   "source": [
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XdSlhAQnDEA"
   },
   "source": [
    "## The Model\n",
    "Base of of Deep Speech 2 with some personal improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "65H1-PCjm-FB"
   },
   "outputs": [],
   "source": [
    "class SpeechRecognitionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuguNEzKnMOn"
   },
   "source": [
    "## The Training and Evaluating Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment, accelerator):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    with experiment.train():\n",
    "        for batch_idx, _data in enumerate(train_loader):\n",
    "            torch.autograd.set_detect_anomaly(True)\n",
    "            \n",
    "            spectrograms, labels, input_lengths, label_lengths = _data\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "            \n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            accelerator.backward(loss)\n",
    "\n",
    "            experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
    "            experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            iter_meter.step()\n",
    "            if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(spectrograms), data_len,\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, epoch, iter_meter, experiment, accelerator):\n",
    "    print('\\nevaluating...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "    with experiment.test():\n",
    "        with torch.no_grad():\n",
    "            for i, _data in enumerate(test_loader):\n",
    "                spectrograms, labels, input_lengths, label_lengths = _data\n",
    "\n",
    "                output = model(spectrograms)  # (batch, time, n_class)\n",
    "                output = F.log_softmax(output, dim=2)\n",
    "                output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "                loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "                test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "                decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "                for j in range(len(decoded_preds)):\n",
    "                    test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                    test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "\n",
    "    avg_cer = sum(test_cer) / len(test_cer)\n",
    "    avg_wer = sum(test_wer) / len(test_wer)\n",
    "    experiment.log_metric('test_loss', test_loss, step=iter_meter.get())\n",
    "    experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
    "    experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(\n",
    "        test_loss, avg_cer, avg_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qBGdkQSmW3a"
   },
   "source": [
    "## Setting up Comet\n",
    "If you have a comet account, fill in teh api key, project name and experiment name below. You can create an account at [comet.ml](comet.ml)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxRIb_WempDq"
   },
   "source": [
    "## GPU runtime\n",
    "If you are using a GPU runtime, this will let you know what GPU and how much memory is available. Adjust your batch_size depending on which GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlUSuAJwlzo8",
    "outputId": "9d01ebfc-4853-4a00-c51f-d0685f9abe80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep  4 16:32:20 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    38W / 250W |   2586MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:02:00.0 Off |                    0 |\n",
      "| N/A   49C    P0    32W / 250W |      4MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2546      C   /usr/bin/python3                 2582MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXvlWZeVpXfX"
   },
   "source": [
    "## Train\n",
    "this will download the data on first run and may take a while.\n",
    "\n",
    "If you have Comet.ml setup, you can start seeing your progress in the comet cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function():\n",
    "    comet_api_key = \"GUmMcuBnNsVBJjnslfRGmqKkI\" # add your api key here\n",
    "    project_name = \"TatAsr\"\n",
    "    experiment_name = \"TatAsr-cnn-rnn-accelerator-2gpu\"\n",
    "\n",
    "    experiment = Experiment(\n",
    "        api_key=comet_api_key, \n",
    "        project_name=project_name, \n",
    "        parse_args=False, \n",
    "        log_code=True, \n",
    "        auto_output_logging=\"default\"\n",
    "    )\n",
    "\n",
    "    experiment.set_name(experiment_name)\n",
    "\n",
    "    set_seed(42)\n",
    "    torch.manual_seed(7)\n",
    "    \n",
    "    accelerator = Accelerator()\n",
    "    \n",
    "    ips_dataset_train = IPS1ASRDataset('../tatar_tts/train/')\n",
    "    ips_dataset_valid = IPS1ASRDataset('../tatar_tts/valid/')\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    learning_rate *= 2\n",
    "    batch_size = 32\n",
    "    epochs = 30\n",
    "    MODEL_PATH = './models/TatAsr-1-accelerator-epoch-8'\n",
    "    \n",
    "    hparams = {\n",
    "        \"n_cnn_layers\": 6,\n",
    "        \"n_rnn_layers\": 10,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 40, # Длина алфавита\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\": 2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "    model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], \n",
    "        hparams['n_rnn_layers'], \n",
    "        hparams['rnn_dim'],\n",
    "        hparams['n_class'], \n",
    "        hparams['n_feats'], \n",
    "        hparams['stride'], \n",
    "        hparams['dropout']\n",
    "    )\n",
    "\n",
    "    experiment.log_parameters(hparams)\n",
    "    \n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "        dataset=ips_dataset_train,\n",
    "        batch_size=hparams['batch_size'],\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda x: data_processing(x, 'train'),\n",
    "    )\n",
    "    \n",
    "    test_loader = data.DataLoader(\n",
    "        dataset=ips_dataset_valid,\n",
    "        batch_size=hparams['batch_size'],\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "    )\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = nn.CTCLoss(blank=39, zero_infinity=True) # Длина алфавита - 1\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=hparams['learning_rate'],\n",
    "        steps_per_epoch=int(len(train_loader)),\n",
    "        epochs=hparams['epochs'],\n",
    "        anneal_strategy='linear'\n",
    "    )\n",
    "\n",
    "    iter_meter = IterMeter()\n",
    "    \n",
    "    model, optimizer, train_loader, test_loader, scheduler, experiment = accelerator.prepare(\n",
    "        model, optimizer, train_loader, test_loader, scheduler, experiment\n",
    "    )\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment, accelerator)\n",
    "        test(model, test_loader, criterion, epoch, iter_meter, experiment, accelerator)\n",
    "        accelerator.save_model(model, f'./models/TatAsr-1-accelerator-epoch-1-{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XZodve8PGKfS",
    "outputId": "d1448327-81d3-4b68-8854-8223a5bcadbc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/gumaonelove/tatasr/588ba7d0444f4853891d0c1aec28f388\n",
      "\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/gumaonelove/tatasr/860281c8e87e4c0e8543ffdb98368ae7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/65891 (0%)]\tLoss: 11.775883\n",
      "Train Epoch: 1 [0/65891 (0%)]\tLoss: 11.804658\n",
      "Train Epoch: 1 [3200/65891 (10%)]\tLoss: 3.158333Train Epoch: 1 [3200/65891 (10%)]\tLoss: 3.182629\n",
      "\n",
      "Train Epoch: 1 [6400/65891 (19%)]\tLoss: 3.143218Train Epoch: 1 [6400/65891 (19%)]\tLoss: 3.161114\n",
      "\n",
      "Train Epoch: 1 [9600/65891 (29%)]\tLoss: 3.180115Train Epoch: 1 [9600/65891 (29%)]\tLoss: 3.145785\n",
      "\n",
      "Train Epoch: 1 [12800/65891 (39%)]\tLoss: 3.159667Train Epoch: 1 [12800/65891 (39%)]\tLoss: 3.135064\n",
      "\n",
      "Train Epoch: 1 [16000/65891 (49%)]\tLoss: 3.125676\n",
      "Train Epoch: 1 [16000/65891 (49%)]\tLoss: 3.160417\n",
      "Train Epoch: 1 [19200/65891 (58%)]\tLoss: 3.176437Train Epoch: 1 [19200/65891 (58%)]\tLoss: 3.171360\n",
      "\n",
      "Train Epoch: 1 [22400/65891 (68%)]\tLoss: 3.131578Train Epoch: 1 [22400/65891 (68%)]\tLoss: 3.135775\n",
      "\n",
      "Train Epoch: 1 [25600/65891 (78%)]\tLoss: 3.128535\n",
      "Train Epoch: 1 [25600/65891 (78%)]\tLoss: 3.142517\n",
      "Train Epoch: 1 [28800/65891 (87%)]\tLoss: 3.132756Train Epoch: 1 [28800/65891 (87%)]\tLoss: 3.145756\n",
      "\n",
      "Train Epoch: 1 [32000/65891 (97%)]\tLoss: 3.157986Train Epoch: 1 [32000/65891 (97%)]\tLoss: 3.160485\n",
      "\n",
      "\n",
      "evaluating...\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 3.1438, Average CER: 0.970308 Average WER: 1.0000\n",
      "\n",
      "Test set: Average loss: 3.1461, Average CER: 0.969484 Average WER: 1.0000\n",
      "\n",
      "Train Epoch: 2 [0/65891 (0%)]\tLoss: 3.157881Train Epoch: 2 [0/65891 (0%)]\tLoss: 3.142207\n",
      "\n",
      "Train Epoch: 2 [3200/65891 (10%)]\tLoss: 3.144423Train Epoch: 2 [3200/65891 (10%)]\tLoss: 3.105868\n",
      "\n",
      "Train Epoch: 2 [6400/65891 (19%)]\tLoss: 3.206545Train Epoch: 2 [6400/65891 (19%)]\tLoss: 3.198717\n",
      "\n",
      "Train Epoch: 2 [9600/65891 (29%)]\tLoss: 3.148629Train Epoch: 2 [9600/65891 (29%)]\tLoss: 3.162471\n",
      "\n",
      "Train Epoch: 2 [12800/65891 (39%)]\tLoss: 3.180170\n",
      "Train Epoch: 2 [12800/65891 (39%)]\tLoss: 3.145732\n",
      "Train Epoch: 2 [16000/65891 (49%)]\tLoss: 3.105117\n",
      "Train Epoch: 2 [16000/65891 (49%)]\tLoss: 3.150989\n",
      "Train Epoch: 2 [19200/65891 (58%)]\tLoss: 3.130151Train Epoch: 2 [19200/65891 (58%)]\tLoss: 3.163804\n",
      "\n",
      "Train Epoch: 2 [22400/65891 (68%)]\tLoss: 3.163541Train Epoch: 2 [22400/65891 (68%)]\tLoss: 3.207681\n",
      "\n",
      "Train Epoch: 2 [25600/65891 (78%)]\tLoss: 3.200464\n",
      "Train Epoch: 2 [25600/65891 (78%)]\tLoss: 3.150915\n",
      "Train Epoch: 2 [28800/65891 (87%)]\tLoss: 3.150297Train Epoch: 2 [28800/65891 (87%)]\tLoss: 3.152637\n",
      "\n",
      "Train Epoch: 2 [32000/65891 (97%)]\tLoss: 3.157105\n",
      "Train Epoch: 2 [32000/65891 (97%)]\tLoss: 3.167503\n",
      "\n",
      "evaluating...\n",
      "evaluating...\n",
      "\n",
      "Test set: Average loss: 3.1854, Average CER: 0.992068 Average WER: 0.9996\n",
      "\n",
      "Test set: Average loss: 3.1840, Average CER: 0.992030 Average WER: 0.9998\n",
      "\n",
      "Train Epoch: 3 [0/65891 (0%)]\tLoss: 3.131213Train Epoch: 3 [0/65891 (0%)]\tLoss: 3.178705\n",
      "\n",
      "Train Epoch: 3 [3200/65891 (10%)]\tLoss: 3.181072\n",
      "Train Epoch: 3 [3200/65891 (10%)]\tLoss: 3.150539\n",
      "Train Epoch: 3 [6400/65891 (19%)]\tLoss: 3.211451Train Epoch: 3 [6400/65891 (19%)]\tLoss: 3.171488\n",
      "\n",
      "Train Epoch: 3 [9600/65891 (29%)]\tLoss: 3.143242Train Epoch: 3 [9600/65891 (29%)]\tLoss: 3.148562\n",
      "\n",
      "Train Epoch: 3 [12800/65891 (39%)]\tLoss: 3.149050\n",
      "Train Epoch: 3 [12800/65891 (39%)]\tLoss: 3.151454\n",
      "Train Epoch: 3 [16000/65891 (49%)]\tLoss: 3.165617Train Epoch: 3 [16000/65891 (49%)]\tLoss: 3.149948\n",
      "\n",
      "Train Epoch: 3 [19200/65891 (58%)]\tLoss: 3.120943\n",
      "Train Epoch: 3 [19200/65891 (58%)]\tLoss: 3.177450\n",
      "Train Epoch: 3 [22400/65891 (68%)]\tLoss: 3.162253Train Epoch: 3 [22400/65891 (68%)]\tLoss: 3.160128\n",
      "\n",
      "Train Epoch: 3 [25600/65891 (78%)]\tLoss: 3.159806Train Epoch: 3 [25600/65891 (78%)]\tLoss: 3.191534\n",
      "\n",
      "Train Epoch: 3 [28800/65891 (87%)]\tLoss: 3.163140Train Epoch: 3 [28800/65891 (87%)]\tLoss: 3.186719\n",
      "\n",
      "Train Epoch: 3 [32000/65891 (97%)]\tLoss: 3.171547Train Epoch: 3 [32000/65891 (97%)]\tLoss: 3.172486\n",
      "\n",
      "\n",
      "evaluating...\n",
      "evaluating...\n",
      "\n",
      "Test set: Average loss: 3.1813, Average CER: 0.992030 Average WER: 0.9998\n",
      "\n",
      "Test set: Average loss: 3.1827, Average CER: 0.992068 Average WER: 0.9996\n",
      "\n",
      "Train Epoch: 4 [0/65891 (0%)]\tLoss: 3.151621\n",
      "Train Epoch: 4 [0/65891 (0%)]\tLoss: 3.177350\n",
      "Train Epoch: 4 [3200/65891 (10%)]\tLoss: 3.154597Train Epoch: 4 [3200/65891 (10%)]\tLoss: 3.131276\n",
      "\n",
      "Train Epoch: 4 [6400/65891 (19%)]\tLoss: 3.163949\n",
      "Train Epoch: 4 [6400/65891 (19%)]\tLoss: 3.168097\n",
      "Train Epoch: 4 [9600/65891 (29%)]\tLoss: 3.114470Train Epoch: 4 [9600/65891 (29%)]\tLoss: 3.152194\n",
      "\n",
      "Train Epoch: 4 [12800/65891 (39%)]\tLoss: 3.131732Train Epoch: 4 [12800/65891 (39%)]\tLoss: 3.145708\n",
      "\n",
      "Train Epoch: 4 [16000/65891 (49%)]\tLoss: 3.135719Train Epoch: 4 [16000/65891 (49%)]\tLoss: 3.153821\n",
      "\n",
      "Train Epoch: 4 [19200/65891 (58%)]\tLoss: 3.140030Train Epoch: 4 [19200/65891 (58%)]\tLoss: 3.185232\n",
      "\n",
      "Train Epoch: 4 [22400/65891 (68%)]\tLoss: 3.141921Train Epoch: 4 [22400/65891 (68%)]\tLoss: 3.217270\n",
      "\n",
      "Train Epoch: 4 [25600/65891 (78%)]\tLoss: 3.134296Train Epoch: 4 [25600/65891 (78%)]\tLoss: 3.135667\n",
      "\n",
      "Train Epoch: 4 [28800/65891 (87%)]\tLoss: 3.149640Train Epoch: 4 [28800/65891 (87%)]\tLoss: 3.183885\n",
      "\n",
      "Train Epoch: 4 [32000/65891 (97%)]\tLoss: 3.141191Train Epoch: 4 [32000/65891 (97%)]\tLoss: 3.142113\n",
      "\n",
      "\n",
      "evaluating...\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 3.1774, Average CER: 0.992068 Average WER: 0.9996\n",
      "\n",
      "Test set: Average loss: 3.1755, Average CER: 0.992030 Average WER: 0.9998\n",
      "\n",
      "Train Epoch: 5 [0/65891 (0%)]\tLoss: 3.153818Train Epoch: 5 [0/65891 (0%)]\tLoss: 3.190351\n",
      "\n",
      "Train Epoch: 5 [3200/65891 (10%)]\tLoss: 3.152035Train Epoch: 5 [3200/65891 (10%)]\tLoss: 3.159045\n",
      "\n",
      "Train Epoch: 5 [6400/65891 (19%)]\tLoss: 3.129074Train Epoch: 5 [6400/65891 (19%)]\tLoss: 3.181637\n",
      "\n",
      "Train Epoch: 5 [9600/65891 (29%)]\tLoss: 3.129778Train Epoch: 5 [9600/65891 (29%)]\tLoss: 3.170453\n",
      "\n",
      "Train Epoch: 5 [12800/65891 (39%)]\tLoss: 3.145541Train Epoch: 5 [12800/65891 (39%)]\tLoss: 3.180713\n",
      "\n",
      "Train Epoch: 5 [16000/65891 (49%)]\tLoss: 3.208866Train Epoch: 5 [16000/65891 (49%)]\tLoss: 3.132934\n",
      "\n",
      "Train Epoch: 5 [19200/65891 (58%)]\tLoss: 3.228281Train Epoch: 5 [19200/65891 (58%)]\tLoss: 3.216521\n",
      "\n",
      "Train Epoch: 5 [22400/65891 (68%)]\tLoss: 3.209413Train Epoch: 5 [22400/65891 (68%)]\tLoss: 3.138264\n",
      "\n",
      "Train Epoch: 5 [25600/65891 (78%)]\tLoss: 3.171998\n",
      "Train Epoch: 5 [25600/65891 (78%)]\tLoss: 3.118097\n",
      "Train Epoch: 5 [28800/65891 (87%)]\tLoss: 3.166797Train Epoch: 5 [28800/65891 (87%)]\tLoss: 3.158958\n",
      "\n",
      "Train Epoch: 5 [32000/65891 (97%)]\tLoss: 3.134318Train Epoch: 5 [32000/65891 (97%)]\tLoss: 3.145426\n",
      "\n",
      "\n",
      "evaluating...\n",
      "evaluating...\n",
      "\n",
      "Test set: Average loss: 3.1821, Average CER: 0.992030 Average WER: 0.9998\n",
      "\n",
      "Test set: Average loss: 3.1836, Average CER: 0.992068 Average WER: 0.9996\n",
      "\n",
      "Train Epoch: 6 [0/65891 (0%)]\tLoss: 3.150677Train Epoch: 6 [0/65891 (0%)]\tLoss: 3.116712\n",
      "\n",
      "Train Epoch: 6 [3200/65891 (10%)]\tLoss: 3.125732Train Epoch: 6 [3200/65891 (10%)]\tLoss: 3.127896\n",
      "\n",
      "Train Epoch: 6 [6400/65891 (19%)]\tLoss: 3.170099\n",
      "Train Epoch: 6 [6400/65891 (19%)]\tLoss: 3.120750\n",
      "Train Epoch: 6 [9600/65891 (29%)]\tLoss: 3.130171Train Epoch: 6 [9600/65891 (29%)]\tLoss: 3.195455\n",
      "\n",
      "Train Epoch: 6 [12800/65891 (39%)]\tLoss: 3.157498Train Epoch: 6 [12800/65891 (39%)]\tLoss: 3.162598\n",
      "\n",
      "Train Epoch: 6 [16000/65891 (49%)]\tLoss: 3.154169Train Epoch: 6 [16000/65891 (49%)]\tLoss: 3.165482\n",
      "\n",
      "Train Epoch: 6 [19200/65891 (58%)]\tLoss: 3.128600Train Epoch: 6 [19200/65891 (58%)]\tLoss: 3.170333\n",
      "\n",
      "Train Epoch: 6 [22400/65891 (68%)]\tLoss: 3.145507Train Epoch: 6 [22400/65891 (68%)]\tLoss: 3.200825\n",
      "\n",
      "Train Epoch: 6 [25600/65891 (78%)]\tLoss: 3.116507Train Epoch: 6 [25600/65891 (78%)]\tLoss: 3.154479\n",
      "\n",
      "Train Epoch: 6 [28800/65891 (87%)]\tLoss: 3.157041Train Epoch: 6 [28800/65891 (87%)]\tLoss: 3.135756\n",
      "\n",
      "Train Epoch: 6 [32000/65891 (97%)]\tLoss: 3.181564Train Epoch: 6 [32000/65891 (97%)]\tLoss: 3.176124\n",
      "\n",
      "\n",
      "evaluating...\n",
      "evaluating...\n",
      "\n",
      "Test set: Average loss: 3.1798, Average CER: 0.992068 Average WER: 0.9996\n",
      "\n",
      "Test set: Average loss: 3.1787, Average CER: 0.992030 Average WER: 0.9998\n",
      "\n",
      "Train Epoch: 7 [0/65891 (0%)]\tLoss: 3.140462Train Epoch: 7 [0/65891 (0%)]\tLoss: 3.090865\n",
      "\n",
      "Train Epoch: 7 [3200/65891 (10%)]\tLoss: 3.131324Train Epoch: 7 [3200/65891 (10%)]\tLoss: 3.166783\n",
      "\n",
      "Train Epoch: 7 [6400/65891 (19%)]\tLoss: 3.144290Train Epoch: 7 [6400/65891 (19%)]\tLoss: 3.204525\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m notebook_launcher(training_function, num_processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/accelerate/launchers.py:154\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaunching training on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_processes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GPUs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     start_processes(launcher, args\u001b[38;5;241m=\u001b[39margs, nprocs\u001b[38;5;241m=\u001b[39mnum_processes, start_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfork\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:197\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mjoin():\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:109\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m ready \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinels\u001b[38;5;241m.\u001b[39mkeys(),\n\u001b[1;32m    111\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m error_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentinel \u001b[38;5;129;01min\u001b[39;00m ready:\n",
      "File \u001b[0;32m~/miniconda3/envs/asr/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/asr/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "notebook_launcher(training_function, num_processes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92kVVEr7GR6j"
   },
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucfQX3qN21az"
   },
   "source": [
    "## Результаты обучения\n",
    "### Модель \n",
    "Использовалась модель из статьи [Building an End-to-End Speech Recognition Model in PyTorch](https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch/) **Deep Speech 2**. \n",
    "\n",
    "### Гипер параметры\n",
    "* `n_cnn_layers` = 3\n",
    "* `n_rnn_layers` = 5\n",
    "* `rnn_dim` = 512\n",
    "* `n_class` = 29\n",
    "* `n_feats` = 128\n",
    "* `stride` = 2\n",
    "* `dropout` = 0.1\n",
    "* `learning_rate` = 0.001\n",
    "* `batch_size` = 80\n",
    "* `epochs` = 10\n",
    "* `num_workers` = 8\n",
    "\n",
    "### Метрики\n",
    "Ниже будут приведены средний \n",
    "* `CER` - частота ошибок в символах\n",
    "* `WER` - частота ошибок в словах\n",
    "\n",
    "Формула расчета\n",
    "**WER** = (S+D+I)/N = (S+D+I)/(S+D+C), где:\n",
    "\n",
    "* **S** — количество замен\n",
    "* **D** — количество удалений\n",
    "* **I** — количество вставок\n",
    "* **C** — количество корректных слов\n",
    "* **N** — количество слов в исходной строке\n",
    "\n",
    "Итоговык метрики \n",
    "* `CER` = 0.24 \n",
    "* `WER` = 0.80\n",
    "\n",
    "### Выводы\n",
    "1. Обучать ASR на одной видео карте **tesla v100** вышеупомянутую модель 2.5 часа, из-за этого проблематично тестировать гипотезы и количество слоев в данной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "asr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
