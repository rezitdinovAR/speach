{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade comet_ml -qq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T16:50:38.118293Z",
     "iopub.status.busy": "2023-09-04T16:50:38.117992Z",
     "iopub.status.idle": "2023-09-04T16:50:50.571885Z",
     "shell.execute_reply": "2023-09-04T16:50:50.570848Z",
     "shell.execute_reply.started": "2023-09-04T16:50:38.118267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-13 14:18:03,425] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "\n",
    "from accelerate import notebook_launcher\n",
    "from accelerate.utils import set_seed\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import clean_text\n",
    "from whisper_dataset import WhisperDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHISPER_MODEL examples:\n",
    "\n",
    "* 1) openai/whisper-small (suitable for testing functionality, not very accurate on sentences, but capable of recognizing individual words or phrases. Requires low computational resources)\n",
    "* 2) openai/whisper-medium (recommended medium model)\n",
    "* 3) openai/whisper-large (sufficiently accurate on large sentences, but requires significant computational resources)\n",
    "* 4) openai/whisper-large-v2 (sufficiently accurate on large sentences, but requires significant computational resources)\n",
    "* 5) lorenzoncina/whisper-medium-ru (a model finetuned on the Russian language - recommended for training on Russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T16:50:50.574473Z",
     "iopub.status.busy": "2023-09-04T16:50:50.573546Z",
     "iopub.status.idle": "2023-09-04T16:50:50.615610Z",
     "shell.execute_reply": "2023-09-04T16:50:50.614730Z",
     "shell.execute_reply.started": "2023-09-04T16:50:50.574437Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"COMET_LOG_ASSETS\"] = \"True\"\n",
    "\n",
    "WHISPER_MODEL = 'openai/whisper-small'\n",
    "DATASET_DIR = '/kaggle/input/it-spectrum-dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T16:50:50.619311Z",
     "iopub.status.busy": "2023-09-04T16:50:50.619037Z",
     "iopub.status.idle": "2023-09-04T16:51:32.900398Z",
     "shell.execute_reply": "2023-09-04T16:51:32.899357Z",
     "shell.execute_reply.started": "2023-09-04T16:50:50.619288Z"
    }
   },
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(WHISPER_MODEL)\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(WHISPER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T16:51:32.904246Z",
     "iopub.status.busy": "2023-09-04T16:51:32.903878Z",
     "iopub.status.idle": "2023-09-04T16:51:32.909408Z",
     "shell.execute_reply": "2023-09-04T16:51:32.908477Z",
     "shell.execute_reply.started": "2023-09-04T16:51:32.904212Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting the model's language and defining the task of transcription\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"tatar\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data initializing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset. When indexed, it returns a list containing:\n",
    "\n",
    "* 1) filepath - path to the audio\n",
    "* 2) text - transcribed text by annotators\n",
    "* 3) input_features - audio features for prediction\n",
    "* 4) labels - transcribed text by annotators converted into tokens\n",
    "* 5) attention mask - an attention mask where each element indicates whether the model should pay attention to the token corresponding to the same index in the labels list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class WhisperDataset(Dataset):\n",
    "    def __init__(self, audio_dir: str, processor, max_length, only_char=True):\n",
    "        self.audio_dir = audio_dir\n",
    "        df = pd.read_csv(audio_dir[:-1] + '.csv', index_col='id')\n",
    "        self.data = {}\n",
    "        counter = 0\n",
    "        for row in df.itertuples():\n",
    "            if not os.path.exists(audio_dir + str(row[0]) + '.txt'):\n",
    "                print('Отсутствует файл', str(row[0]) + '.txt')\n",
    "                continue\n",
    "            if not os.path.exists(audio_dir + str(row[0]) + '.wav'):\n",
    "                print(f'Отсутствует файл', str(row[0]) + '.wav')\n",
    "                continue\n",
    "            self.data[counter] = {\n",
    "                'text': str(row[0]) + '.txt',\n",
    "                'audio': str(row[0]) + '.wav'\n",
    "            }\n",
    "            counter += 1\n",
    "        self.len = counter - 1\n",
    "        self.only_char = only_char\n",
    "        del counter\n",
    "        del df\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def _get_audio_sample_path(self, index):\n",
    "        return self.audio_dir + self.data[index]['audio']\n",
    "    \n",
    "    def _get_audio_sample_label(self, index):\n",
    "        label_path = self.audio_dir + self.data[index]['text']\n",
    "        with open(label_path, 'r') as f:\n",
    "            label = clean_text(f.read()) if self.only_char else f.read() # Не учитывает ошибки в заполнение .txt\n",
    "        return label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self._get_audio_sample_path(idx)\n",
    "        text = self._get_audio_sample_label(idx)\n",
    "        \n",
    "        audio, sample_rate = torchaudio.load(filepath)\n",
    "        audio = torch.reshape(audio, (-1,))\n",
    "        \n",
    "        tokenized = self.processor.tokenizer(\n",
    "            text, return_tensors='pt', padding='max_length', return_attention_mask=True, \n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        \n",
    "        labels, attention_mask = tokenized['input_ids'][0], tokenized['attention_mask'][0]\n",
    "        \n",
    "        input_features = self.processor(audio, return_tensors=\"pt\", sampling_rate=sample_rate).input_features[0]\n",
    "        \n",
    "        return {\n",
    "            'input_features': input_features, \n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T16:51:33.332146Z",
     "iopub.status.busy": "2023-09-04T16:51:33.331814Z",
     "iopub.status.idle": "2023-09-04T16:51:33.338088Z",
     "shell.execute_reply": "2023-09-04T16:51:33.337238Z",
     "shell.execute_reply.started": "2023-09-04T16:51:33.332116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отсутствует файл 331.26.txt\n",
      "Отсутствует файл 338.17.txt\n",
      "Отсутствует файл 177.2.txt\n",
      "Отсутствует файл 18.3.txt\n",
      "Отсутствует файл 83.3.txt\n",
      "Отсутствует файл 339.14.txt\n",
      "Отсутствует файл 103.3.txt\n",
      "Отсутствует файл 334.12.txt\n",
      "Отсутствует файл 327.4.txt\n",
      "Отсутствует файл 477.26.txt\n",
      "Отсутствует файл 329.3.txt\n",
      "Отсутствует файл 328.11.txt\n",
      "Отсутствует файл 337.23.txt\n",
      "Отсутствует файл 68.3.txt\n",
      "Отсутствует файл 121.3.txt\n",
      "Отсутствует файл 305.6.txt\n",
      "Отсутствует файл 436.4.txt\n",
      "Отсутствует файл 95.1.txt\n",
      "Отсутствует файл 303.27.txt\n",
      "Отсутствует файл 315.4.txt\n",
      "Отсутствует файл 340.3.txt\n",
      "Отсутствует файл 302.1.txt\n",
      "Отсутствует файл 335.8.txt\n",
      "Отсутствует файл 138.2.txt\n",
      "Отсутствует файл 153.2.txt\n",
      "Отсутствует файл 99.3.txt\n",
      "Отсутствует файл 196.3.txt\n",
      "Отсутствует файл 314.2.txt\n",
      "Отсутствует файл 333.3.txt\n",
      "Отсутствует файл 310.12.txt\n",
      "Отсутствует файл 120.2.txt\n",
      "Отсутствует файл 8.3.txt\n",
      "Отсутствует файл 87.2.txt\n",
      "Отсутствует файл 119.3.txt\n",
      "Отсутствует файл 103.2.txt\n",
      "Отсутствует файл 119.2.txt\n",
      "Отсутствует файл 496.19.txt\n",
      "Отсутствует файл 91.3.txt\n",
      "Отсутствует файл 170.2.txt\n",
      "Отсутствует файл 178.2.txt\n",
      "Отсутствует файл 100.2.txt\n",
      "Отсутствует файл 104.2.txt\n",
      "Отсутствует файл 336.21.txt\n",
      "Отсутствует файл 307.18.txt\n",
      "Отсутствует файл 336.1.txt\n",
      "Отсутствует файл 382.15.txt\n",
      "Отсутствует файл 338.26.txt\n",
      "Отсутствует файл 342.5.txt\n",
      "Отсутствует файл 100.3.txt\n",
      "Отсутствует файл 302.1.txt\n",
      "Отсутствует файл 161.3.txt\n",
      "Отсутствует файл 42.3.txt\n",
      "Отсутствует файл 345.3.txt\n",
      "Отсутствует файл 333.3.txt\n",
      "Отсутствует файл 327.4.txt\n",
      "Отсутствует файл 108.3.txt\n",
      "Отсутствует файл 183.3.txt\n",
      "Отсутствует файл 353.38.txt\n",
      "Отсутствует файл 104.1.txt\n",
      "Отсутствует файл 84.3.txt\n",
      "Отсутствует файл 153.3.txt\n",
      "Отсутствует файл 463.27.txt\n",
      "Отсутствует файл 331.22.txt\n",
      "Отсутствует файл 329.3.txt\n",
      "Отсутствует файл 319.3.txt\n",
      "Отсутствует файл 99.1.txt\n",
      "Отсутствует файл 99.2.txt\n",
      "Отсутствует файл 319.14.txt\n",
      "Отсутствует файл 89.3.txt\n",
      "Отсутствует файл 94.3.txt\n",
      "Отсутствует файл 331.9.txt\n",
      "Отсутствует файл 256.76.txt\n",
      "Отсутствует файл 178.3.txt\n",
      "Отсутствует файл 303.8.txt\n",
      "Отсутствует файл 335.3.txt\n",
      "Отсутствует файл 253.25.txt\n",
      "Отсутствует файл 304.4.txt\n",
      "Отсутствует файл 340.26.txt\n",
      "Отсутствует файл 327.2.txt\n",
      "Отсутствует файл 331.39.txt\n",
      "Отсутствует файл 329.14.txt\n",
      "Отсутствует файл 304.23.txt\n",
      "Отсутствует файл 339.26.txt\n",
      "Отсутствует файл 498.26.txt\n",
      "Отсутствует файл 80.3.txt\n",
      "Отсутствует файл 109.3.txt\n",
      "Отсутствует файл 198.3.txt\n",
      "Отсутствует файл 317.5.txt\n",
      "Отсутствует файл 321.9.txt\n",
      "Отсутствует файл 104.3.txt\n",
      "Отсутствует файл 324.9.txt\n",
      "Отсутствует файл 335.38.txt\n",
      "Отсутствует файл 342.4.txt\n",
      "Отсутствует файл 91.1.txt\n",
      "Отсутствует файл 303.3.txt\n",
      "Отсутствует файл 154.2.txt\n",
      "Отсутствует файл 87.1.txt\n",
      "Отсутствует файл 302.8.txt\n",
      "Отсутствует файл 267.74.txt\n",
      "Отсутствует файл 494.7.txt\n",
      "Отсутствует файл 108.1.txt\n",
      "Отсутствует файл 119.1.txt\n",
      "Отсутствует файл 330.3.txt\n",
      "Отсутствует файл 300.15.txt\n",
      "Отсутствует файл 84.1.txt\n",
      "Отсутствует файл 334.7.txt\n",
      "Отсутствует файл 120.1.txt\n",
      "Отсутствует файл 319.16.txt\n",
      "Отсутствует файл 333.22.txt\n",
      "Отсутствует файл 492.4.txt\n",
      "Отсутствует файл 305.19.txt\n",
      "Отсутствует файл 96.2.txt\n",
      "Отсутствует файл 95.3.txt\n",
      "Отсутствует файл 333.26.txt\n",
      "Отсутствует файл 96.1.txt\n",
      "Отсутствует файл 90.3.txt\n",
      "Отсутствует файл 308.6.txt\n",
      "Отсутствует файл 324.14.txt\n",
      "Отсутствует файл 253.57.txt\n",
      "Отсутствует файл 91.2.txt\n",
      "Отсутствует файл 120.3.txt\n",
      "Отсутствует файл 84.2.txt\n",
      "Отсутствует файл 34.3.txt\n",
      "Отсутствует файл 129.2.txt\n",
      "Отсутствует файл 479.26.txt\n",
      "Отсутствует файл 83.1.txt\n",
      "Отсутствует файл 193.3.txt\n",
      "Отсутствует файл 129.3.txt\n",
      "Отсутствует файл 337.22.txt\n",
      "Отсутствует файл 332.29.txt\n",
      "Отсутствует файл 309.22.txt\n",
      "Отсутствует файл 310.27.txt\n",
      "Отсутствует файл 170.3.txt\n",
      "Отсутствует файл 138.3.txt\n",
      "Отсутствует файл 420.21.txt\n",
      "Отсутствует файл 194.2.txt\n",
      "Отсутствует файл 332.38.txt\n",
      "Отсутствует файл 162.2.txt\n",
      "Отсутствует файл 485.19.txt\n",
      "Отсутствует файл 154.3.txt\n",
      "Отсутствует файл 96.3.txt\n",
      "Отсутствует файл 337.33.txt\n",
      "Отсутствует файл 116.2.txt\n",
      "Отсутствует файл 340.3.txt\n",
      "Отсутствует файл 300.11.txt\n",
      "Отсутствует файл 318.12.txt\n",
      "Отсутствует файл 305.26.txt\n",
      "Отсутствует файл 116.1.txt\n",
      "Отсутствует файл 162.3.txt\n",
      "Отсутствует файл 361.38.txt\n",
      "Отсутствует файл 116.3.txt\n",
      "Отсутствует файл 327.2.txt\n",
      "Отсутствует файл 39.3.txt\n",
      "Отсутствует файл 335.3.txt\n",
      "Отсутствует файл 471.8.txt\n",
      "Отсутствует файл 103.1.txt\n",
      "Отсутствует файл 342.4.txt\n",
      "Отсутствует файл 315.5.txt\n",
      "Отсутствует файл 494.19.txt\n",
      "Отсутствует файл 128.3.txt\n",
      "Отсутствует файл 100.1.txt\n",
      "Отсутствует файл 304.8.txt\n",
      "Отсутствует файл 108.2.txt\n",
      "Отсутствует файл 83.2.txt\n",
      "Отсутствует файл 306.14.txt\n",
      "Отсутствует файл 264.25.txt\n",
      "Отсутствует файл 177.3.txt\n",
      "Отсутствует файл 430.26.txt\n",
      "Отсутствует файл 302.13.txt\n",
      "Отсутствует файл 338.14.txt\n",
      "Отсутствует файл 320.3.txt\n",
      "Отсутствует файл 321.24.txt\n",
      "Отсутствует файл 334.29.txt\n",
      "Отсутствует файл 316.2.txt\n",
      "Отсутствует файл 31.3.txt\n",
      "Отсутствует файл 332.37.txt\n",
      "Отсутствует файл 74.3.txt\n",
      "Отсутствует файл 329.16.txt\n",
      "Отсутствует файл 193.2.txt\n",
      "Отсутствует файл 342.12.txt\n",
      "Отсутствует файл 130.3.txt\n",
      "Отсутствует файл 130.2.txt\n",
      "Отсутствует файл 161.2.txt\n",
      "Отсутствует файл 87.3.txt\n",
      "Отсутствует файл 95.2.txt\n",
      "Отсутствует файл 345.3.txt\n",
      "Отсутствует файл 198.2.txt\n",
      "Отсутствует файл 194.3.txt\n",
      "Отсутствует файл 309.13.txt\n",
      "Отсутствует файл 336.1.txt\n",
      "Отсутствует файл 294.38.txt\n",
      "Отсутствует файл 241.2.txt\n",
      "Отсутствует файл 295.8.txt\n",
      "Отсутствует файл 241.3.txt\n",
      "Отсутствует файл 224.3.txt\n",
      "Отсутствует файл 227.2.txt\n",
      "Отсутствует файл 298.7.txt\n",
      "Отсутствует файл 282.16.txt\n",
      "Отсутствует файл 217.3.txt\n",
      "Отсутствует файл 299.1.txt\n",
      "Отсутствует файл 272.11.txt\n",
      "Отсутствует файл 297.16.txt\n",
      "Отсутствует файл 294.5.txt\n",
      "Отсутствует файл 298.26.txt\n",
      "Отсутствует файл 293.26.txt\n",
      "Отсутствует файл 293.28.txt\n",
      "Отсутствует файл 292.26.txt\n",
      "Отсутствует файл 272.51.txt\n",
      "Отсутствует файл 280.47.txt\n",
      "Отсутствует файл 228.2.txt\n",
      "Отсутствует файл 296.1.txt\n",
      "Отсутствует файл 295.18.txt\n",
      "Отсутствует файл 297.11.txt\n",
      "Отсутствует файл 284.9.txt\n",
      "Отсутствует файл 227.3.txt\n",
      "Отсутствует файл 224.2.txt\n",
      "Отсутствует файл 299.1.txt\n",
      "Отсутствует файл 295.11.txt\n",
      "Отсутствует файл 238.2.txt\n",
      "Отсутствует файл 228.3.txt\n",
      "Отсутствует файл 238.3.txt\n",
      "Отсутствует файл 202.3.txt\n",
      "Отсутствует файл 288.38.txt\n",
      "Отсутствует файл 292.24.txt\n",
      "Отсутствует файл 291.18.txt\n",
      "Отсутствует файл 295.21.txt\n",
      "Отсутствует файл 290.36.txt\n",
      "Отсутствует файл 202.2.txt\n",
      "Отсутствует файл 222.3.txt\n"
     ]
    }
   ],
   "source": [
    "# create train/val/test datasets\n",
    "train_dataset_1 = WhisperDataset('../../tatar_asr_2/train/', processor, model.config.max_length)\n",
    "train_dataset_2 = WhisperDataset('../../tatar_asr_1/train/', processor, model.config.max_length)\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset_1, train_dataset_2])\n",
    "\n",
    "valid_dataset = WhisperDataset('../../tatar_asr_2/valid/', processor, model.config.max_length)\n",
    "test_dataset = WhisperDataset('../../tatar_asr_1/valid/', processor, model.config.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T16:51:33.340120Z",
     "iopub.status.busy": "2023-09-04T16:51:33.339329Z",
     "iopub.status.idle": "2023-09-04T16:51:33.348751Z",
     "shell.execute_reply": "2023-09-04T16:51:33.347701Z",
     "shell.execute_reply.started": "2023-09-04T16:51:33.340081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173229, 10446)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 13 10:28:11 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    25W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:02:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    28W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_ml.init( project_name = \"TatAsr-whisper\", experiment_name = \"TatAsr-whisper-dataset-all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function():\n",
    "    global model\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./whisper-dataset-all', \n",
    "        overwrite_output_dir=True, \n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=7,\n",
    "        save_steps=500, \n",
    "        save_total_limit=2,\n",
    "        do_train=True,\n",
    "    )\n",
    "    \n",
    "    set_seed(42)\n",
    "    torch.manual_seed(7)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m You are trying to log string value as a metric. This is not recommended.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/gumaonelove/huggingface/66d2f1af52004007b8917086107c326b\n",
      "\n",
      "[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='61870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   15/61870 00:23 < 30:38:38, 0.56 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m notebook_launcher(training_function, num_processes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, mixed_precision\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfp16\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/accelerate/launchers.py:154\u001B[0m, in \u001B[0;36mnotebook_launcher\u001B[0;34m(function, args, num_processes, mixed_precision, use_port)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLaunching training on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_processes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m GPUs.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 154\u001B[0m     start_processes(launcher, args\u001B[38;5;241m=\u001B[39margs, nprocs\u001B[38;5;241m=\u001B[39mnum_processes, start_method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfork\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ProcessRaisedException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    156\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m e\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:197\u001B[0m, in \u001B[0;36mstart_processes\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m context\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mjoin():\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:109\u001B[0m, in \u001B[0;36mProcessContext.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001B[39;00m\n\u001B[0;32m--> 109\u001B[0m ready \u001B[38;5;241m=\u001B[39m multiprocessing\u001B[38;5;241m.\u001B[39mconnection\u001B[38;5;241m.\u001B[39mwait(\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentinels\u001B[38;5;241m.\u001B[39mkeys(),\n\u001B[1;32m    111\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[1;32m    112\u001B[0m )\n\u001B[1;32m    114\u001B[0m error_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sentinel \u001B[38;5;129;01min\u001B[39;00m ready:\n",
      "File \u001B[0;32m~/miniconda3/envs/asr/lib/python3.11/multiprocessing/connection.py:930\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    927\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    929\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 930\u001B[0m     ready \u001B[38;5;241m=\u001B[39m selector\u001B[38;5;241m.\u001B[39mselect(timeout)\n\u001B[1;32m    931\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    932\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m~/miniconda3/envs/asr/lib/python3.11/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selector\u001B[38;5;241m.\u001B[39mpoll(timeout)\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "notebook_launcher(training_function, num_processes=2, mixed_precision='fp16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_model(): \n",
    "    checkpoint_path = max(os.listdir('../whisper-dataset-all'), key=lambda x: int(x.split('-')[-1]) if 'checkpoint-' in x else 0)\n",
    "    checkpoint_path = os.path.join('../whisper-dataset-all', checkpoint_path)\n",
    "    return AutoModelForSpeechSeq2Seq.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:03:47.134928Z",
     "iopub.status.busy": "2023-09-04T17:03:47.134287Z",
     "iopub.status.idle": "2023-09-04T17:03:51.326360Z",
     "shell.execute_reply": "2023-09-04T17:03:51.325346Z",
     "shell.execute_reply.started": "2023-09-04T17:03:47.134896Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_last_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset: WhisperDataset) -> pd.DataFrame:\n",
    "    predicted_df = pd.DataFrame([], columns=['filename', 'pred', 'gt'])\n",
    "    n = len(dataset)\n",
    "    for idx in tqdm(range(100, 200)):\n",
    "        item = dataset[idx]\n",
    "        filepath = dataset._get_audio_sample_path(idx)\n",
    "        text = dataset._get_audio_sample_label(idx)\n",
    "        input_features = item['input_features']\n",
    "        attention_mask = item['attention_mask']\n",
    "        filename = filepath.replace('\\\\', '/').split('/')[-1]\n",
    "        model = model.to('cuda')\n",
    "    \n",
    "        input_features = torch.stack([input_features]).to('cuda')\n",
    "        generated_ids = model.generate(inputs=input_features, attention_mask=attention_mask)\n",
    "        transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "        predicted_df.loc[len(predicted_df)] = [filename, transcription, text]\n",
    "    return predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:03:51.328494Z",
     "iopub.status.busy": "2023-09-04T17:03:51.328121Z",
     "iopub.status.idle": "2023-09-04T17:03:54.221716Z",
     "shell.execute_reply": "2023-09-04T17:03:54.220635Z",
     "shell.execute_reply.started": "2023-09-04T17:03:51.328462Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:45<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_df = predict(model, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:03:54.223590Z",
     "iopub.status.busy": "2023-09-04T17:03:54.223138Z",
     "iopub.status.idle": "2023-09-04T17:03:54.234701Z",
     "shell.execute_reply": "2023-09-04T17:03:54.233633Z",
     "shell.execute_reply.started": "2023-09-04T17:03:54.223541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>pred</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>785_394009940.wav</td>\n",
       "      <td>бинзонның ассистиянең сынар кадәр җылытылган к...</td>\n",
       "      <td>бензолны ацетиленны с кадәр җылытылган күмерле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>888_174014518.wav</td>\n",
       "      <td>икенчесе кысык күзле кып кызыл йөзендә зур бор...</td>\n",
       "      <td>икенчесе кысык күзле кып кызыл йөзендә зур бор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67_721826785.wav</td>\n",
       "      <td>тавык күркә бытбылдык үрдәк каз итләре рөхсәт ...</td>\n",
       "      <td>тавык күркә бытбылдык үрдәк каз итләре рөхсәт ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>766_1304178405.wav</td>\n",
       "      <td>минем бик зур гүләтнең коллекциясе җыелды</td>\n",
       "      <td>минем бик зур бюллетень коллекциясе җыелды</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>886_443528311.wav</td>\n",
       "      <td>матбугат конференциясе дә атысы билгеле иде ин...</td>\n",
       "      <td>матбугат конференциясе датасы билгеле иде инде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>882_853742303.wav</td>\n",
       "      <td>хәзерге украина хакимияте берничә ел уйлаган м...</td>\n",
       "      <td>хәзерге украина хакимияте берничә ел уйлаган м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>838_1140452245.wav</td>\n",
       "      <td>бу бер өлеш турында зур булмаган инсидент була...</td>\n",
       "      <td>бу бәрелеш турында зур булмаган инцидент булар...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>801_893117302.wav</td>\n",
       "      <td>әлбәттә безнең даими игътибар зонасында тышкы ...</td>\n",
       "      <td>әлбәттә безнең даими игътибар зонасында тышкы ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>880_987311976.wav</td>\n",
       "      <td>татарстан республикасы предприятиене рәхм оешм...</td>\n",
       "      <td>татарстан республикасы предприятиеләре һәм оеш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>829_1127518106.wav</td>\n",
       "      <td>елда татарстан республикасында алтмыш авыл тор...</td>\n",
       "      <td>елда татарстан республикасында авыл торак пунк...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                               pred  \\\n",
       "0    785_394009940.wav  бинзонның ассистиянең сынар кадәр җылытылган к...   \n",
       "1    888_174014518.wav  икенчесе кысык күзле кып кызыл йөзендә зур бор...   \n",
       "2     67_721826785.wav  тавык күркә бытбылдык үрдәк каз итләре рөхсәт ...   \n",
       "3   766_1304178405.wav          минем бик зур гүләтнең коллекциясе җыелды   \n",
       "4    886_443528311.wav  матбугат конференциясе дә атысы билгеле иде ин...   \n",
       "..                 ...                                                ...   \n",
       "95   882_853742303.wav  хәзерге украина хакимияте берничә ел уйлаган м...   \n",
       "96  838_1140452245.wav  бу бер өлеш турында зур булмаган инсидент була...   \n",
       "97   801_893117302.wav  әлбәттә безнең даими игътибар зонасында тышкы ...   \n",
       "98   880_987311976.wav  татарстан республикасы предприятиене рәхм оешм...   \n",
       "99  829_1127518106.wav  елда татарстан республикасында алтмыш авыл тор...   \n",
       "\n",
       "                                                   gt  \n",
       "0   бензолны ацетиленны с кадәр җылытылган күмерле...  \n",
       "1   икенчесе кысык күзле кып кызыл йөзендә зур бор...  \n",
       "2   тавык күркә бытбылдык үрдәк каз итләре рөхсәт ...  \n",
       "3          минем бик зур бюллетень коллекциясе җыелды  \n",
       "4   матбугат конференциясе датасы билгеле иде инде...  \n",
       "..                                                ...  \n",
       "95  хәзерге украина хакимияте берничә ел уйлаган м...  \n",
       "96  бу бәрелеш турында зур булмаган инцидент булар...  \n",
       "97  әлбәттә безнең даими игътибар зонасында тышкы ...  \n",
       "98  татарстан республикасы предприятиеләре һәм оеш...  \n",
       "99  елда татарстан республикасында авыл торак пунк...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:03:54.236945Z",
     "iopub.status.busy": "2023-09-04T17:03:54.236278Z",
     "iopub.status.idle": "2023-09-04T17:03:54.245320Z",
     "shell.execute_reply": "2023-09-04T17:03:54.244367Z",
     "shell.execute_reply.started": "2023-09-04T17:03:54.236910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0%\n"
     ]
    }
   ],
   "source": [
    "# metric: accuracy\n",
    "acc = sum((predicted_df['pred'] == predicted_df['gt'])) / len(predicted_df)\n",
    "print(f'{acc * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom sample test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:03:54.247339Z",
     "iopub.status.busy": "2023-09-04T17:03:54.246977Z",
     "iopub.status.idle": "2023-09-04T17:03:54.257558Z",
     "shell.execute_reply": "2023-09-04T17:03:54.256699Z",
     "shell.execute_reply.started": "2023-09-04T17:03:54.247307Z"
    }
   },
   "outputs": [],
   "source": [
    "audio, sample_rate = librosa.load(os.path.join(DATASET_DIR, 'sample/eu.0124f456-13b8-4765-936a-36bfd483683e.wav'), sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:03:54.259598Z",
     "iopub.status.busy": "2023-09-04T17:03:54.259174Z",
     "iopub.status.idle": "2023-09-04T17:03:54.319455Z",
     "shell.execute_reply": "2023-09-04T17:03:54.318206Z",
     "shell.execute_reply.started": "2023-09-04T17:03:54.259545Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = processor(audio, return_tensors='pt', sampling_rate=sample_rate)\n",
    "input_features = inputs.input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:03:54.321383Z",
     "iopub.status.busy": "2023-09-04T17:03:54.321037Z",
     "iopub.status.idle": "2023-09-04T17:03:54.506578Z",
     "shell.execute_reply": "2023-09-04T17:03:54.505617Z",
     "shell.execute_reply.started": "2023-09-04T17:03:54.321352Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(inputs=input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:03:54.508427Z",
     "iopub.status.busy": "2023-09-04T17:03:54.508090Z",
     "iopub.status.idle": "2023-09-04T17:03:54.516341Z",
     "shell.execute_reply": "2023-09-04T17:03:54.515232Z",
     "shell.execute_reply.started": "2023-09-04T17:03:54.508396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новая\n"
     ]
    }
   ],
   "source": [
    "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "asr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
